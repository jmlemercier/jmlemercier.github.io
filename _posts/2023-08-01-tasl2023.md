---
layout: post
author: jmlemercier
date: 2023-08-01
title: StoRM - A diffusion-based stochastic regeneration model for speech enhancement and dereverberation
excerpt: Published in IEEE Transactions on Audio, Speech and Language Processing.
authors: Jean-Marie Lemercier, Julius Richter, Simon Welker, Timo Gerkmann
keywords: Diffusion Models, Speech Enhancement, Dereverberation, Neural network
---

<div class="post-image">
<img src="/assets/tasl2023/inference.png" height="200px">
</div>

<div class="links">
<p>
Available on <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10180108"> IEEE Xplore </a> and on <a href="https://arxiv.org/pdf/2212.11851"> arXiv </a>.
</p>
<p>
Code published on <a href="https://github.com/sp-uhh/storm"> GitHub </a>.
</p>
<p>
Audio examples on our <a href="https://www.inf.uni-hamburg.de/en/inst/ab/sp/publications/storm.html"> companion website </a>.
</p>
</div>

<div class="abstract">
<p>
Diffusion models have shown a great ability at bridging the performance gap between predictive and generative approaches for speech enhancement. We have shown that they may even outperform their predictive counterparts for non-additive corruption types or when they are evaluated on mismatched conditions. However, diffusion models suffer from a high computational burden, mainly as they require to run a neural network for each reverse diffusion step, whereas predictive approaches only require one pass. As diffusion models are generative approaches they may also produce vocalizing and breathing artifacts in adverse conditions. In comparison, in such difficult scenarios, predictive models typically do not produce
such artifacts but tend to distort the target speech instead, thereby degrading the speech quality.
</p>
<p>
In this work, we present a stochastic regeneration approach where an estimate given by a predictive model is provided as a guide for further diffusion. We show that the proposed approach uses the predictive model to remove the vocalizing and breathing artifacts while producing very high quality samples thanks to the diffusion model, even in adverse conditions. We further show that this approach enables to use lighter sampling schemes with fewer diffusion steps without sacrificing quality, thus lifting the computational burden by an order of magnitude. Source code and audio examples are available online.
</p>
</div>