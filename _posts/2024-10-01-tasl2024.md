---
layout: post
author: jmlemercier
date: 2024-10-01
title: Unsupervised Blind Joint Dereverberation and Room Acoustics Estimation with Diffusion Models
excerpt: Submitted to IEEE Transactions on Audio, Speech and Language Processing
authors: Jean-Marie Lemercier, Eloi Moliner, Simon Welker, Vesa Välimäki, Timo Gerkmann
keywords: Diffusion Models, Speech Dereverberation, Inverse Problems, Unsupervised Learning
---

<div class="post-image">
<img src="/assets/tasl2024/tasl.png" height="900px">
</div>

<div class="links">
<p>
Available on <a href="https://arxiv.org/abs/2408.07472"> arXiv </a>.
</p>
</div>

<div class="abstract">
<p>
This paper presents an unsupervised method for single-channel blind dereverberation and room impulse response (RIR) estimation, called BUDDy. The algorithm is rooted in Bayesian posterior sampling: it combines a likelihood model enforcing fidelity to the reverberant measurement, and an anechoic speech prior implemented by an unconditional diffusion model. We design a parametric filter representing the RIR, with exponential decay for each frequency subband. Room acoustics estimation and speech dereverberation are jointly carried out, as the filter parameters are iteratively estimated and the speech utterance refined along the reverse diffusion trajectory. In a blind scenario where the RIR is unknown, BUDDy successfully performs speech dereverberation in various acoustic scenarios, significantly outperforming other blind unsupervised baselines. Unlike supervised methods, which often struggle to generalize, BUDDy seamlessly adapts to different acoustic conditions.
</p>
<p>
This paper extends our previous work by offering new experimental results and insights into the algorithm's versatility. We demonstrate the robustness of our proposed method to new acoustic and speaker conditions, as well as its adaptability to high-resolution singing voice dereverberation, using both instrumental metrics and subjective listening evaluation. We study BUDDy's performance for RIR estimation and observe it surpasses a state-of-the-art supervised DNN-based estimator on mismatched acoustic conditions. Finally, we investigate the sensitivity of informed dereverberation methods to RIR estimation errors, thereby motivating the joint acoustic estimation and dereverberation design. Audio examples and code can be found online. 
</p>
</div>